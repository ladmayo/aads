def minmax(x,a,b): #a: min b:max
    return(2*(x-a)/(b-a)-1)
def invminmax(x,a,b):
    return((b+a+x*(b-a))/2)
def get_data(len_input_lstm,mode,horizon=24*3,num=1):
    if mode=="tr":
        data_tr=pd.read_csv(wd+"1_Data_preprocess\\"+
                            "scaled\\Tr_"+str(num)+".csv")
        Data_tr=pd.read_csv(wd+"1_Data_preprocess\\"+
                            "unscaled\\Tr_"+str(num)+".csv")
        var=data_tr.values[10:,1:].astype("float64")
        VAR=Data_tr.values[10:,1:].astype("float64")
        dates=data_tr.values[10:,0]
    elif mode=="val":
        data_tr=pd.read_csv(wd+"1_Data_preprocess\\"+
                            "scaled\\Tr_"+str(num)+".csv")
        Data_tr=pd.read_csv(wd+"1_Data_preprocess\\"+
                            "unscaled\\Tr_"+str(num)+".csv")
        data_val=pd.read_csv(wd+"1_Data_preprocess\\"+
                            "scaled\\Val_"+str(num)+".csv")
        Data_val=pd.read_csv(wd+"1_Data_preprocess\\"+
                            "unscaled\\Val_"+str(num)+".csv")
        var=np.concatenate((data_tr.values[-len_input_lstm-horizon+10:,1:],
                            data_val.values[:,1:]),axis=0).astype("float64")
        VAR=np.concatenate((Data_tr.values[-len_input_lstm-horizon+10:,1:],
                            Data_val.values[:,1:]),axis=0).astype("float64")
        dates=np.concatenate((data_tr.values[-len_input_lstm-horizon+10:,0],
                            data_val.values[:,0]),axis=0)
    len_var=var.shape[0]
    var=np.asarray([var[o*24:o*24+len_input_lstm+horizon,:] 
                          for o in range(1+int((len_var-len_input_lstm-horizon)/24))])
    VAR=np.asarray([VAR[o*24:o*24+len_input_lstm+horizon,:] 
                          for o in range(1+int((len_var-len_input_lstm-horizon)/24))])
    date=np.asarray([dates[o*24+len_input_lstm] for o in range(1+int((len_var-len_input_lstm-horizon)/24))])
    #Se pasa a kW
    VAR[:,:,pv_ind]=VAR[:,:,pv_ind]/1000
    Ebat=np.random.uniform(E_min,E_max,(var.shape[0],1))
    P_dam=np.random.uniform(LAMBDA_neg,LAMBDA_pos,(var.shape[0],14))
    P_damru=np.random.uniform(0,asl,(var.shape[0],14))
    P_damrd=np.random.uniform(0,asl,(var.shape[0],14))
    P_rtpd=np.random.uniform(LAMBDA_neg-np.repeat(P_dam[:,0:1],4,axis=1),LAMBDA_pos-np.repeat(P_dam[:,0:1],4,axis=1),
                         (var.shape[0],4))
    buffer=[var,VAR,P_dam,P_damru,P_damrd,P_rtpd,Ebat,date]
    return(buffer)

class DamActorNetwork(object):
    def __init__(self,l_lstm1,n_lstm1,n_lstm2,n_dense):
        (self.l_lstm1,self.n_lstm1,self.n_lstm2,
         self.n_dense)=(l_lstm1,n_lstm1,n_lstm2,n_dense)
    def create_network(self):
        initializer = tf.keras.initializers.GlorotUniform()
        input_lstm1 = input_layer.Input(shape=(self.l_lstm1, 9))
        lstm_1=layers.LSTM(self.n_lstm1, activation='tanh', kernel_initializer=initializer,dropout=0.2,
                         return_sequences=False)(input_lstm1)
        input_lstm2= input_layer.Input(shape=(14, 6))
        lstm_2=layers.LSTM(self.n_lstm2, activation='tanh', kernel_initializer=initializer,dropout=0.2,
                         return_sequences=False)(input_lstm2)
        input_clock=input_layer.Input(shape=(4))
        input_rtpd=input_layer.Input(shape=(4))
        input_e0=input_layer.Input(shape=(1))

        input_dense=layers.Concatenate()([lstm_1,lstm_2,input_clock,input_rtpd,input_e0])
        input_dense=layers.BatchNormalization()(input_dense)
        dense = layers.Dense(self.n_dense[0], activation=["tanh","relu"][int(len(self.n_dense)>1)],
                             use_bias=True, 
                             kernel_initializer=initializer)(input_dense)
        for i in range(len(self.n_dense)-1):
            dense=tf.keras.layers.Dropout(0.2)(dense)
            dense = layers.Dense(self.n_dense[i+1],
                                 activation='tanh',
                                 use_bias=True, kernel_initializer=initializer)(dense)
        self.model=models.Model(inputs=[input_lstm1,input_lstm2,input_clock,input_rtpd,input_e0], outputs=dense)

class RtpdActorNetwork(object):
    def __init__(self,l_lstm0,l_lstm1,n_lstm0,n_lstm1,n_lstm2,n_dense):
        (self.l_lstm0,self.l_lstm1,self.n_lstm0,self.n_lstm1,self.n_lstm2,
         self.n_dense)=(l_lstm0,l_lstm1,n_lstm0,n_lstm1,n_lstm2,n_dense)
    def create_network(self):
        initializer = tf.keras.initializers.GlorotUniform()
        input_lstm0 = input_layer.Input(shape=(self.l_lstm0*60, 2))
        lstm_0=layers.LSTM(self.n_lstm0, activation='tanh',
                         return_sequences=False, kernel_initializer=initializer,dropout=0.2)(input_lstm0)
        
        input_lstm1 = input_layer.Input(shape=(self.l_lstm1*4, 5))
        lstm_1=layers.LSTM(self.n_lstm1, activation='tanh',
                         return_sequences=False, kernel_initializer=initializer,dropout=0.2)(input_lstm1)
        
        input_lstm2= input_layer.Input(shape=(12, 6))
        lstm_2=layers.LSTM(self.n_lstm2, activation='tanh',
                         return_sequences=False, kernel_initializer=initializer,dropout=0.2)(input_lstm2)
        input_clock=input_layer.Input(shape=(6))
        input_rtpd=input_layer.Input(shape=(4))
        input_e0=input_layer.Input(shape=(1))
        input_dense=layers.Concatenate()([lstm_0,lstm_1,lstm_2,input_clock,input_rtpd,input_e0])
        input_dense=layers.BatchNormalization()(input_dense)
        dense = layers.Dense(self.n_dense[0], activation=["tanh","relu"][int(len(self.n_dense)>1)],
                             use_bias=True, kernel_initializer=initializer)(input_dense)
        for i in range(len(self.n_dense)-1):
            dense=tf.keras.layers.Dropout(0.2)(dense)
            dense = layers.Dense(self.n_dense[i+1],
                                 activation='tanh',
                                 use_bias=True)(dense)
        self.model=models.Model(inputs=[input_lstm0,input_lstm1,input_lstm2,input_clock,input_rtpd,input_e0], outputs=dense)
        
def update_target(actor,target_actor,tau):
    new_weights = []
    target_variables = target_actor.weights
    for i, variable in enumerate(actor.model.weights):
        new_weights.append(variable * tau + target_variables[i] * (1 - tau))
    target_actor.set_weights(new_weights)
    return(target_actor)
def random_anns_params():
    dam_len_lstm=np.random.randint(3,9)*24
    dam_lstm1_ann=np.random.randint(10,64,1)[0]
    dam_lstm2_ann=np.random.randint(10,64,1)[0]
    dam_deep_dense=np.random.randint(1,3,1)[0]
    dam_dense_ann=[np.random.randint(40,100,1)[0]]
    for i in range(dam_deep_dense): dam_dense_ann.append(np.random.randint(20,100,1)[0])
    dam_dense_ann[-1]=24*3

    rtpd_len_lstm=np.random.randint(1,3)*24
    rtpd_len_lstm0=np.random.randint(1,4)
    rtpd_lstm0_ann=np.random.randint(10,64,1)[0]
    rtpd_lstm1_ann=np.random.randint(10,64,1)[0]
    rtpd_lstm2_ann=np.random.randint(10,64,1)[0]
    rtpd_deep_dense=np.random.randint(1,3,1)[0]
    rtpd_dense_ann=[np.random.randint(40,100,1)[0]]
    for i in range(rtpd_deep_dense): rtpd_dense_ann.append(np.random.randint(20,100,1)[0])
    rtpd_dense_ann[-1]=4
    
    DAM_params=[dam_len_lstm,dam_lstm1_ann,dam_lstm2_ann,dam_dense_ann]
    RTPD_params=[rtpd_len_lstm0,rtpd_len_lstm,rtpd_lstm0_ann,rtpd_lstm1_ann,rtpd_lstm2_ann,rtpd_dense_ann]
    return(DAM_params,RTPD_params)

def buffer_sample(mode,buff,params,batch_size=None,idx=None):
    #Aca se inicializan los parametros, en la función de training se usa un random para asignar estos valores
    horizon,dam_len_lstm,rtpd_len_lstm0,rtpd_len_lstm=params
    if mode=="tr":
        #Se escogen días al azar hasta hacer un grupo de 16
        idx=np.random.choice(np.arange(buff[0].shape[0]), size=batch_size,replace=False)
        #Cada buffer esta asociado a un "saco de datos"
        buffer=[buff[s][idx] for s in range(len(buff))] #var,VAR,P_dam,P_damru,P_damrd,P_rtpd,Ebat
    elif mode=="val":
        batch_size=buff[0].shape[0]
        idx=np.arange(batch_size)
        buffer=[buff[s][idx] for s in range(len(buff))]
    
    #condiciones iniciales
    b_dam=tf.convert_to_tensor(buffer[2].reshape(batch_size,14),dtype="float32")#DAM
    b_damru=tf.convert_to_tensor(buffer[3].reshape(batch_size,14),dtype="float32")#DAMru
    b_damrd=tf.convert_to_tensor(buffer[4].reshape(batch_size,14),dtype="float32")#DAMrd
    b_rtpd=tf.convert_to_tensor(buffer[5].reshape(batch_size,4),dtype="float32")#RTPD
    Eo=tf.convert_to_tensor(buffer[6][:,0:1],dtype="float32")#E0
    #------DAM data
    [clock_dam,clock_dam_d1,clock_dam_d2]=[buffer[0][:,-horizon+o][:,damclock_ind] for o in [0,24,48]] #reloj
        
    #Se cargan los valores como tal
    [dam_lstm1,dam_lstm1_d1,dam_lstm1_d2]=[np.concatenate((buffer[0][:,-dam_len_lstm-horizon+o:-horizon+o][:,:,dam_ind],
                    buffer[0][:,-dam_len_lstm-horizon+o:-horizon+o][:,:,damru_ind],
                    buffer[0][:,-dam_len_lstm-horizon+o:-horizon+o][:,:,damrd_ind],
                    np.mean(buffer[0][:,-dam_len_lstm-horizon+o:-horizon+o][:,:,rt_ind],axis=2).reshape(batch_size,-1,1),
                    np.std(buffer[0][:,-dam_len_lstm-horizon+o:-horizon+o][:,:,rt_ind],axis=2).reshape(batch_size,-1,1),
                    np.mean(buffer[0][:,-dam_len_lstm-horizon+o:-horizon+o][:,:,pv_ind],axis=2).reshape(batch_size,-1,1),
                    np.std(buffer[0][:,-dam_len_lstm-horizon+o:-horizon+o][:,:,pv_ind],axis=2).reshape(batch_size,-1,1),
                    np.mean(buffer[0][:,-dam_len_lstm-horizon+o:-horizon+o][:,:,agc_ind],axis=2).reshape(batch_size,-1,1),
                    np.std(buffer[0][:,-dam_len_lstm-horizon+o:-horizon+o][:,:,agc_ind],axis=2).reshape(batch_size,-1,1)),axis=2)
                                          for o in [0,24,48]]
    [dam_lstm2,dam_lstm2_d1,dam_lstm2_d2]=[np.concatenate((buffer[0][:,-horizon+o:-horizon+14+o][:,:,dam_ind],
                            buffer[0][:,-horizon+o:-horizon+14+o][:,:,damru_ind],
                                            buffer[0][:,-horizon+o:-horizon+14+o][:,:,damrd_ind],
                             minmax(buffer[2].reshape(batch_size,14,1),LAMBDA_neg,LAMBDA_pos),
                            minmax(buffer[3].reshape(batch_size,14,1),0,asl),
                            minmax(buffer[4].reshape(batch_size,14,1),0,asl)),axis=2) for o in [0,24,48]] 
                                            #to replace buffer values and flip

    #----- RTPD data
    clock_rtpd=buffer[0][:,-horizon:][:,:,rtmclock_ind]
    rtpd_lstm0=np.concatenate((
        buffer[0][:,-rtpd_len_lstm0-horizon:][:,:,pv_ind].reshape(batch_size,-1,1),
        buffer[0][:,-rtpd_len_lstm0-horizon:][:,:,agc_ind].reshape(batch_size,-1,1)),axis=2)
    rtpd_lstm1=np.concatenate((
        buffer[0][:,-rtpd_len_lstm-horizon:][:,:,rt_ind].reshape(batch_size,-1,1),
        np.mean(buffer[0][:,-rtpd_len_lstm-horizon:][:,:,pv_ind].reshape(batch_size,-1,15), axis=2).reshape(batch_size,-1,1),
        np.std(buffer[0][:,-rtpd_len_lstm-horizon:][:,:,pv_ind].reshape(batch_size,-1,15), axis=2).reshape(batch_size,-1,1),
        np.mean(buffer[0][:,-rtpd_len_lstm-horizon:][:,:,agc_ind].reshape(batch_size,-1,15), axis=2).reshape(batch_size,-1,1),
        np.std(buffer[0][:,-rtpd_len_lstm-horizon:][:,:,agc_ind].reshape(batch_size,-1,15), axis=2).reshape(batch_size,-1,1)),axis=2)
    rtpd_lstm2_prov=np.concatenate((buffer[0][:,-horizon:][:,:,dam_ind].reshape(batch_size,horizon,1),
                                   buffer[0][:,-horizon:][:,:,damru_ind].reshape(batch_size,horizon,1),
                                   buffer[0][:,-horizon:][:,:,damrd_ind].reshape(batch_size,horizon,1)),axis=2) 
                                                    #to add decisions DAM and flip

    #---- Loss calculation
    pv_gen=buffer[1][:,-horizon:][:,:,pv_ind]
    AGC=buffer[1][:,-horizon:][:,:,agc_ind]
    AGCup=AGC*(AGC>0)
    AGCdn=-AGC*(AGC<0)
    RTPD_price=buffer[1][:,-horizon:][:,:,rt_ind].reshape(batch_size,horizon*4)
    DAM_price=buffer[1][:,-horizon:][:,:,dam_ind].reshape(batch_size,horizon)
    DAMru_price=buffer[1][:,-horizon:][:,:,damru_ind].reshape(batch_size,horizon)
    DAMrd_price=buffer[1][:,-horizon:][:,:,damrd_ind].reshape(batch_size,horizon)
    date=buffer[7]
    Batch=[idx,b_dam,b_damru,b_damrd,b_rtpd,Eo,clock_dam,clock_dam_d1,clock_dam_d2,
           dam_lstm1,dam_lstm1_d1,dam_lstm1_d2,dam_lstm2,dam_lstm2_d1,dam_lstm2_d2,
           clock_rtpd,rtpd_lstm0,rtpd_lstm1,rtpd_lstm2_prov,
           pv_gen,AGCup,AGCdn,RTPD_price,DAM_price,DAMru_price,DAMrd_price,date]
    return(Batch)

def run(mode,batch_size,params,tr_buffer,val_buffer,
    plot=True,epochs=None,rew_tr=None,idx=None):
    if mode=="tr":
        batch=buffer_sample("tr",tr_buffer,params,batch_size,None)
    elif mode=="val":
        batch_size=val_buffer[0].shape[0]
        batch=buffer_sample("val",val_buffer,params,None,None)

    [idx,b_dam,b_damru,b_damrd,b_rtpd,Eo,clock_dam,clock_dam_d1,clock_dam_d2,
               dam_lstm1,dam_lstm1_d1,dam_lstm1_d2,dam_lstm2,dam_lstm2_d1,dam_lstm2_d2,
               clock_rtpd,rtpd_lstm0,rtpd_lstm1,rtpd_lstm2_prov,
               pv_gen,AGCup,AGCdn,RTPD_price,DAM_price,DAMru_price,DAMrd_price,date]=batch
    check_hrs=False
    delta_xi,delta_q=1/60,1/4
    for hr in range(horizon_sim): # hr 0 is 10 am day D, hr 14 is 0 am day D+1, hr 24 is 10 am day D+1
        if hr==14 or hr==14+24: day+=1
        #--------------------------DAMS ANNS
        if hr==0: # DAM model
            day=0
            if check_hrs: print("DAM ann | Hour:",hr+10-day*24,"Day:",day)
            # collect initial conditions schedule
            DAM_sch,DAMru_sch,DAMrd_sch=b_dam,b_damru,b_damrd
            RTPD_sch=b_rtpd
            #action
            dam_lstm2=np.flip(dam_lstm2,axis=1)
            dam_action=tf.reshape(act_dam.model([dam_lstm1,dam_lstm2,clock_dam,
                               minmax(RTPD_sch[:,-4:],
                                       LAMBDA_neg-np.repeat(DAM_sch[:,hr:hr+1],4,axis=1),
                                       LAMBDA_pos-np.repeat(DAM_sch[:,hr:hr+1],4,axis=1)),
                                                 minmax(Eo[:,-1:],E_min,E_max)]),
                                  (batch_size,24,3))
            #transform output range
            A_dam,A_damru,A_damrd=(invminmax(dam_action[:,:,0],LAMBDA_neg,LAMBDA_pos),
                                   invminmax(dam_action[:,:,1],0,asl),invminmax(dam_action[:,:,2],0,asl))
            #expand schedule
            DAM_sch,DAMru_sch,DAMrd_sch=(tf.concat((DAM_sch,A_dam),axis=1),
                                         tf.concat((DAMru_sch,A_damru),axis=1),tf.concat((DAMrd_sch,A_damrd),axis=1))
            #updates initial conditions buffers (Dam,Damru,Damrd)
            if mode=="tr":
                idxu=idx[idx<(tr_buffer[0].shape[0]-1)]+1
                tr_buffer[2][idxu],tr_buffer[3][idxu],tr_buffer[4][idxu]=(A_dam.numpy()[idx<(tr_buffer[0].shape[0]-1)][:,-14:],
                                    A_damru.numpy()[idx<(tr_buffer[0].shape[0]-1)][:,-14:],A_damrd.numpy()[idx<(tr_buffer[0].shape[0]-1)][:,-14:])
                if sum(idx<(tr_buffer[0].shape[0]-1))!=batch_size:
                    val_buffer[2][0],val_buffer[3][0],val_buffer[4][0]=(A_dam.numpy()[idx==(tr_buffer[0].shape[0]-1)][:,-14:],
                                    A_damru.numpy()[idx==(tr_buffer[0].shape[0]-1)][:,-14:],A_damrd.numpy()[idx==(tr_buffer[0].shape[0]-1)][:,-14:])
            elif mode=="val":
                idxu=idx[idx<(val_buffer[0].shape[0]-1)]+1
                val_buffer[2][idxu],val_buffer[3][idxu],val_buffer[4][idxu]=(A_dam.numpy()[idx<(val_buffer[0].shape[0]-1)][:,-14:],
                                    A_damru.numpy()[idx<(val_buffer[0].shape[0]-1)][:,-14:],A_damrd.numpy()[idx<(val_buffer[0].shape[0]-1)][:,-14:])
                
        if hr==24 or hr==48: # DAM CLONE model
            if check_hrs: print("DAM_clone ann | Hour:",hr+10-day*24,"Day:",day)
            if hr==24:
                dam_lstm1_nd=dam_lstm1_d1
                dam_lstm2_nd=dam_lstm2_d1
                clock_dam_nd=clock_dam_d1
            else:
                dam_lstm1_nd=dam_lstm1_d2
                dam_lstm2_nd=dam_lstm2_d2
                clock_dam_nd=clock_dam_d2
            #update dam_lstm2_nd input in accordance to schedule and flip
            dam_lstm2_nd[:,:,3]=minmax(DAM_sch[:,-14:],LAMBDA_neg,LAMBDA_pos)
            dam_lstm2_nd[:,:,4]=minmax(DAMru_sch[:,-14:],0,asl)
            dam_lstm2_nd[:,:,5]=minmax(DAMrd_sch[:,-14:],0,asl)
            dam_lstm2_nd=np.flip(dam_lstm2_nd,axis=1)
            #action
            dam_action_nd=tf.reshape(act_dam_clone([dam_lstm1_nd,dam_lstm2_nd,clock_dam_nd,
                    minmax(RTPD_sch[:,-4:],LAMBDA_neg-np.repeat(DAM_sch[:,hr:hr+1],4,axis=1),
                                       LAMBDA_pos-np.repeat(DAM_sch[:,hr:hr+1],4,axis=1)),
                                                    minmax(Eo[:,-1:],E_min,E_max)]),(batch_size,24,3))
            #transform output range
            A_dam_nd,A_damru_nd,A_damrd_nd=(invminmax(dam_action_nd[:,:,0],LAMBDA_neg,LAMBDA_pos),
                                   invminmax(dam_action_nd[:,:,1],0,asl),invminmax(dam_action_nd[:,:,2],0,asl))
            #expand schedule
            DAM_sch,DAMru_sch,DAMrd_sch=(tf.concat((DAM_sch,A_dam_nd),axis=1),
                                tf.concat((DAMru_sch,A_damru_nd),axis=1),tf.concat((DAMrd_sch,A_damrd_nd),axis=1))
            #updates initial conditions buffers (Ebat)
            if hr==24:
                if mode=="tr":
                    idxu=idx[idx<(tr_buffer[0].shape[0]-1)]+1
                    tr_buffer[6][idxu]=Eo.numpy()[idx<(tr_buffer[0].shape[0]-1)][:,-1:]
                    if sum(idx<(tr_buffer[0].shape[0]-1))!=batch_size:
                        val_buffer[6][0]=Eo.numpy()[idx==(tr_buffer[0].shape[0]-1)][:,-1:]
                elif mode=="val":
                    idxu=idx[idx<(val_buffer[0].shape[0]-1)]+1
                    val_buffer[6][idxu]=Eo.numpy()[idx<(val_buffer[0].shape[0]-1)][:,-1:]

        #--------------------------RTPDS ANNS
        if hr<horizon_sim-1: #not necessary to take rtm decisions for an extra hour
            #add DAM decisions and flip
            rtpd_lstm2=tf.concat((rtpd_lstm2_prov[:,hr:12+hr,:],
                tf.reshape(minmax(DAM_sch[:,hr:12+hr],LAMBDA_neg,LAMBDA_pos),(batch_size,12,1)),
                tf.reshape(minmax(DAMru_sch[:,hr:12+hr],0,asl),(batch_size,12,1)),
                tf.reshape(minmax(DAMrd_sch[:,hr:12+hr],0,asl),(batch_size,12,1))),axis=2)
            rtpd_lstm2=tf.reverse(rtpd_lstm2,[1])

        if hr<13 or 13+24<=hr<horizon_sim-1: # RTPD clone model
            if check_hrs: print("RTPD_clone ann | Hour:",hr+10-day*24,"Day:",day)
            #actions
            rtpd_action=act_rtpd_clone([rtpd_lstm0[:,60*hr:(60*hr+60*rtpd_len_lstm0),:],
                                           rtpd_lstm1[:,4*hr:(4*hr+4*rtpd_len_lstm),:],
                                           rtpd_lstm2,clock_rtpd[:,hr,:],
                                        minmax(RTPD_sch[:,-4:],
                                                            LAMBDA_neg-np.repeat(DAM_sch[:,hr:hr+1],4,axis=1),
                                       LAMBDA_pos-np.repeat(DAM_sch[:,hr:hr+1],4,axis=1)),
                                                        minmax(Eo[:,-1:],E_min,E_max)])
            #Transform actions
            rtpd_action=invminmax(rtpd_action,LAMBDA_neg-np.repeat(DAM_sch[:,hr+1:hr+2],4,axis=1),
                                       LAMBDA_pos-np.repeat(DAM_sch[:,hr+1:hr+2],4,axis=1))
            #expand schedule
            RTPD_sch=tf.concat((RTPD_sch,rtpd_action),axis=1)
        else: #RTPD model for decisions from 0:00 to 23:00 (take decisions from 23:00 to 22:00)
            if check_hrs: print("RTPD ann | Hour:",hr+10-day*24,"Day:",day)
            #actions
            rtpd_action=act_rtpd.model([rtpd_lstm0[:,60*hr:(60*hr+60*rtpd_len_lstm0),:],
                                        rtpd_lstm1[:,4*hr:(4*hr+4*rtpd_len_lstm),:],
                                        rtpd_lstm2,clock_rtpd[:,hr,:],minmax(RTPD_sch[:,-4:],
                                                            LAMBDA_neg-np.repeat(DAM_sch[:,hr:hr+1],4,axis=1),
                                       LAMBDA_pos-np.repeat(DAM_sch[:,hr:hr+1],4,axis=1)),
                                                        minmax(Eo[:,-1:],E_min,E_max)])
            #Transform actions
            rtpd_action=invminmax(rtpd_action,LAMBDA_neg-np.repeat(DAM_sch[:,hr+1:hr+2],4,axis=1),
                                       LAMBDA_pos-np.repeat(DAM_sch[:,hr+1:hr+2],4,axis=1))
            #expand schedule
            RTPD_sch=tf.concat((RTPD_sch,rtpd_action),axis=1)
            #update buffers (rtpd)
            if hr==23: #hour 9:00 day 0 decides bidding for hour 10:00 
                if mode=="tr":
                    idxu=idx[idx<(tr_buffer[0].shape[0]-1)]+1
                    tr_buffer[5][idxu]=RTPD_sch[idx<(tr_buffer[0].shape[0]-1)][:,-4:]
                    if sum(idx<(tr_buffer[0].shape[0]-1))!=batch_size:
                        val_buffer[5][0]=RTPD_sch[idx==(tr_buffer[0].shape[0]-1)][:,-4:]
                if mode=="val":
                    idxu=idx[idx<(val_buffer[0].shape[0]-1)]+1
                    val_buffer[5][idxu]=RTPD_sch[idx<(val_buffer[0].shape[0]-1)][:,-4:]

        #-------------------------------- DYNAMICs
        p_req=(tf.repeat(RTPD_sch[:,4*hr:4*(hr+1)]+tf.repeat(DAM_sch[:,hr:hr+1],4,axis=1),15,axis=1)-pv_gen[:,hr,:]
              +DAMru_sch[:,hr:hr+1]*AGCup[:,hr,:]-DAMrd_sch[:,hr:hr+1]*AGCdn[:,hr,:])
        if hr==0: Preq=p_req
        else: Preq=tf.concat((Preq,p_req),axis=1)
        for i in range(60): # preq>0 dsg -> p_deliver>0 ||||  p_req<0 chg -> p_deliver<0
            if i==0 and hr==0:
                p_deliver=(-tf.minimum(P_ess,tf.minimum((E_max-Eo[:,-1:])/(nu_chg*delta_xi),tf.maximum(-p_req[:,i:i+1],0)))+
                    tf.minimum(P_ess,tf.minimum(nu_dsg*(Eo[:,-1:]-E_min)/delta_xi,tf.maximum(p_req[:,i:i+1],0))))
            else:
                p_deliver=tf.concat((p_deliver,-tf.minimum(P_ess,tf.minimum((E_max-Eo[:,-1:])/(nu_chg*delta_xi),
                                                                             tf.maximum(-p_req[:,i:i+1],0)))+
                    tf.minimum(P_ess,tf.minimum(nu_dsg*(Eo[:,-1:]-E_min)/delta_xi,tf.maximum(p_req[:,i:i+1],0)))),axis=1)
            Eo=tf.concat((Eo,Eo[:,-1:]+nu_chg*tf.maximum(0,-p_deliver[:,-1:])*delta_xi-
                          (1/nu_dsg)*tf.maximum(0,p_deliver[:,-1:])*delta_xi),axis=1)
    DAM_rev=tf.math.multiply(DAM_price[:,:horizon_sim],DAM_sch[:,:horizon_sim])
    DAMru_rev=tf.math.multiply(DAMru_price[:,:horizon_sim],DAMru_sch[:,:horizon_sim])
    DAMrd_rev=tf.math.multiply(DAMrd_price[:,:horizon_sim],DAMrd_sch[:,:horizon_sim])
    RTPD_rev=tf.math.multiply(RTPD_price[:,:4*horizon_sim],RTPD_sch[:,:4*horizon_sim])/4
    IMB_pen=price_imb*tf.abs(Preq-p_deliver)/60
    rews=(tf.reduce_sum(DAM_rev,axis=1)+tf.reduce_sum(DAMru_rev,axis=1)+tf.reduce_sum(DAMrd_rev,axis=1)+
         tf.reduce_sum(RTPD_rev,axis=1)-tf.reduce_sum(IMB_pen,axis=1))/(horizon_sim*60)
    rew=tf.reduce_mean(rews).numpy()
    
    if plot:
        yl=1.3
        ini=14
        fin=24+14
        plt.rcParams["figure.figsize"]=[16,12]
        ind=np.random.randint(0,len(idx))
        if rew_tr==None and mode=="tr":
            plt.suptitle(date[ind][:-3]+"| Epoch: "+str(epochs)+" | Reward tr. batch set: "+str(np.round(rew,3)),
                         y=1.02,size=18)
        elif mode=="tst":
            plt.suptitle(date[ind][:-3]+"| Epoch: "+str(epochs),
                         y=1.02,size=18)
        else:
            plt.suptitle(date[ind][:-3]+"| Epoch: "+str(epochs)+" | Reward tr. batch set: "+str(np.round(rew_tr,3))+
                         " | Reward val. batch set: "+str(np.round(rew,3)),
                         y=1.02,size=18)
        plt.rcParams["figure.figsize"]=[16,12]
        plt.subplot(6,2,1)
        plt.title("Energy market prices",size=16,y=1.06,horizontalalignment="left",x=0)
        plt.plot(np.repeat(DAM_price[ind,ini:fin],60),"r",linewidth=2.3,label="DAM")
        plt.plot(np.repeat(RTPD_price[ind,ini*4:fin*4],15),"b",linewidth=2.3,label="RTM"),plt.grid()
        plt.xlim([0,int((fin-ini)*60)]),plt.ylabel("$ / MWh",size=14)
        plt.xticks(np.arange(1440)[::60*3],["0:00","3:00","6:00","9:00","12:00","15:00","18:00","21:00","23:00"]),plt.ylabel("$ / MWh",size=14)
        plt.legend(bbox_to_anchor=(.7, 1.05, .3,0), loc='lower left', prop={'size': 12},
               ncol=2, mode="expand", borderaxespad=0.)

        plt.subplot(6,2,2)
        plt.title("A.S market prices",size=16,y=1.06,horizontalalignment="right",x=1)
        plt.plot(np.repeat(DAMru_price[ind,ini:fin],60),"orange",linewidth=2.3,label="Rup")
        plt.plot(np.repeat(DAMrd_price[ind,ini:fin],60),"navy",linewidth=2.3,label="Rdn"),plt.grid()
        plt.xlim([0,int((fin-ini)*60)])
        plt.xticks(np.arange(1440)[::60*3],["0:00","3:00","6:00","9:00","12:00","15:00","18:00","21:00","23:00"])
        plt.legend(bbox_to_anchor=(.0, 1.05, .3,0), loc='lower left', prop={'size': 12},
               ncol=2, mode="expand", borderaxespad=0.)

        plt.subplot(6,2,3)
        plt.title("Energy market scheduling",size=16,y=1.06,horizontalalignment="left",x=0)
        plt.plot(np.repeat(DAM_sch[ind,ini:fin],60),"r",linewidth=2.3,label="DAM")
        plt.plot(np.repeat(RTPD_sch[ind,ini*4:fin*4],15),"b",linewidth=2.3,label="RTM"),plt.grid()
        plt.xlim([0,int((fin-ini)*60)])
        plt.xticks(np.arange(1440)[::60*3],["0:00","3:00","6:00","9:00","12:00","15:00","18:00","21:00","23:00"]),plt.ylabel("MWh",size=14)

        plt.subplot(6,2,4)
        plt.title("A.S market scheduling",size=16,y=1.06,horizontalalignment="right",x=1)
        plt.axhline(y=asl,color="k",linestyle="-.",linewidth=1),plt.axhline(y=0,color="k",linestyle="-.",linewidth=1)
        plt.plot(np.repeat(DAMru_sch[ind,ini:fin],60),"orange",linewidth=2.3,label="Rup")
        plt.plot(np.repeat(DAMrd_sch[ind,ini:fin],60),"navy",linewidth=2.3,label="Rdn"),plt.grid()
        plt.xlim([0,int((fin-ini)*60)])
        plt.xticks(np.arange(1440)[::60*3],["0:00","3:00","6:00","9:00","12:00","15:00","18:00","21:00","23:00"])

        plt.subplot(6,2,5)
        plt.title("Cumulative energy market profits",size=16,y=1.06,horizontalalignment="left",x=0)
        plt.plot(np.repeat(np.cumsum(DAM_rev[ind,ini:fin]),60),"r",label="DAM",linewidth=2.3)
        plt.plot(np.repeat(np.cumsum(RTPD_rev[ind,ini*4:fin*4]),15),"b",label="RTPD",linewidth=2.3),plt.grid()
        plt.xlim([0,int((fin-ini)*60)])
        plt.xticks(np.arange(1440)[::60*3],["0:00","3:00","6:00","9:00","12:00","15:00","18:00","21:00","23:00"])
        plt.ylabel("$",size=14)

        plt.subplot(6,2,6)
        plt.title("Cumulative A.S market profits",size=16,y=1.06,horizontalalignment="right",x=1)
        plt.plot(np.repeat(np.cumsum(DAMru_rev[ind,ini:fin]),60),"orange",label="Rup",linewidth=2.3)
        plt.plot(np.repeat(np.cumsum(DAMrd_rev[ind,ini:fin]),60),"navy",label="Rdn",linewidth=2.3),plt.grid()
        plt.xlim([0,int((fin-ini)*60)])
        plt.xticks(np.arange(1440)[::60*3],["0:00","3:00","6:00","9:00","12:00","15:00","18:00","21:00","23:00"])
        
        plt.subplot(6,1,4)
        plt.title("Cumulative net incomes",size=16,y=1.06,horizontalalignment="left",x=0)
        plt.fill_between(np.arange((fin-ini)*60),
                        np.repeat(np.cumsum(DAM_rev[ind,ini:fin]),60)+np.repeat(np.cumsum(DAMru_rev[ind,ini:fin]),60)+
                         np.repeat(np.cumsum(DAMrd_rev[ind,ini:fin]),60)+
                         np.repeat(np.cumsum(RTPD_rev[ind,ini*4:fin*4]),15),
                        np.repeat(np.cumsum(DAM_rev[ind,ini:fin]),60)+np.repeat(np.cumsum(DAMru_rev[ind,ini:fin]),60)+
                         np.repeat(np.cumsum(DAMrd_rev[ind,ini:fin]),60)+
                         np.repeat(np.cumsum(RTPD_rev[ind,ini*4:fin*4]),15)-np.cumsum(IMB_pen[ind,ini*60:fin*60]),
                 color="cornflowerblue",linewidth=2.3,alpha=0.6)
        plt.plot(np.repeat(np.cumsum(DAM_rev[ind,ini:fin]),60)+np.repeat(np.cumsum(DAMru_rev[ind,ini:fin]),60)+
                         np.repeat(np.cumsum(DAMrd_rev[ind,ini:fin]),60)+
                         np.repeat(np.cumsum(RTPD_rev[ind,ini*4:fin*4]),15),
                 color="green",linewidth=2.3,label="M°s profit")
        plt.plot(np.repeat(np.cumsum(DAM_rev[ind,ini:fin]),60)+np.repeat(np.cumsum(DAMru_rev[ind,ini:fin]),60)+
                         np.repeat(np.cumsum(DAMrd_rev[ind,ini:fin]),60)+
                         np.repeat(np.cumsum(RTPD_rev[ind,ini*4:fin*4]),15)-np.cumsum(IMB_pen[ind,ini*60:fin*60]),
                 color="k",linewidth=2.3,label="M°s profit minus imb. penalty")
        plt.grid()
        plt.legend(bbox_to_anchor=(.7, 1.05, .3,0), loc='lower left',  prop={'size': 12},
                               ncol=2, mode="expand", borderaxespad=0.)
        plt.xlim([0,int((fin-ini)*60)])
        plt.xticks(np.arange(1440)[::60*3],["0:00","3:00","6:00","9:00","12:00","15:00","18:00","21:00","23:00"])
        
        plt.subplot(6,1,5)
        plt.title("Schedule fulfillment",y=1.05,horizontalalignment="left",x=0,size=16)
        plt.fill_between(np.arange((fin-ini)*60),
                        np.repeat(DAM_sch[ind,ini:fin],60)+np.repeat(RTPD_sch[ind,ini*4:fin*4],15),
                np.repeat(DAM_sch[ind,ini:fin],60)+np.repeat(RTPD_sch[ind,ini*4:fin*4],15)+
                 np.repeat(DAMru_sch[ind,ini:fin],60),
                         color="orange",alpha=0.3,label="Rup sch.")
        plt.fill_between(np.arange((fin-ini)*60),
                        np.repeat(DAM_sch[ind,ini:fin],60)+np.repeat(RTPD_sch[ind,ini*4:fin*4],15),
                np.repeat(DAM_sch[ind,ini:fin],60)+np.repeat(RTPD_sch[ind,ini*4:fin*4],15)-
                 np.repeat(DAMrd_sch[ind,ini:fin],60),
                         color="navy",alpha=0.1,label="Rdn sch.")
        plt.plot(pv_gen[ind].reshape(-1)[ini*60:fin*60],"orangered",linewidth=3,label="PV")
        plt.plot(np.repeat(DAM_sch[ind,ini:fin],60)+np.repeat(RTPD_sch[ind,ini*4:fin*4],15),
                 "k-.",linewidth=0.5,label="DAM+RTPD sch.")
        plt.fill_between(np.arange((fin-ini)*60),
                         p_deliver[ind,ini*60:fin*60]+
                         pv_gen[ind].reshape(-1)[ini*60:fin*60]
                            ,Preq[ind,ini*60:fin*60]+
                         pv_gen[ind].reshape(-1)[ini*60:fin*60],color="limegreen",label="Energy imb.")
        plt.plot(Preq[ind,ini*60:fin*60]+
                         pv_gen[ind].reshape(-1)[ini*60:fin*60],
                 "darkred",linewidth=2,label="Request")
        plt.plot(p_deliver[ind,ini*60:fin*60]+
                         pv_gen[ind].reshape(-1)[ini*60:fin*60],
                "navy",linewidth=2,label="Injections"),plt.grid()
        plt.xlim([0,int((fin-ini)*60)])
        plt.xticks(np.arange(1440)[::60*3],["0:00","3:00","6:00","9:00","12:00","15:00","18:00","21:00","23:00"])
        plt.legend(bbox_to_anchor=(.2, 1.05, .8,0), loc='lower left', prop={'size': 12},
               ncol=7, mode="expand", borderaxespad=0.)
        plt.ylabel("MW",size=14)

        plt.subplot(6,1,6)
        Ecap=E_max/0.9
        plt.title("ESS State of Charge",y=1.05,horizontalalignment="left",x=0,size=16)
        plt.fill_between(np.arange((fin-ini)*60),100*E_max/Ecap,100,color="r",alpha=0.3)
        plt.fill_between(np.arange((fin-ini)*60),100*E_min/Ecap,0,color="r",alpha=0.3,label="Forbidden")
        plt.plot(100*Eo[ind,ini*60+1:fin*60+1]/Ecap,color="navy",linewidth=2,label="SoC"),plt.grid()
        plt.xlim([0,int((fin-ini)*60)])
        plt.xticks(np.arange(1440)[::60*3],["0:00","3:00","6:00","9:00","12:00","15:00","18:00","21:00","23:00"])
        plt.ylim([0,100])
        plt.ylabel("%",size=14)
        plt.legend(bbox_to_anchor=(.8, 1.05, .2,0), loc='lower left', prop={'size': 12},
               ncol=2, mode="expand", borderaxespad=0.)
        
        plt.tight_layout()
        plt.show()


    return(rews,rew,tr_buffer,val_buffer)

def training(net,num,off=0):
    np.random.seed(seed=net+(num-1)*10+off) #only modify "off" if there's a size allocation problem
    tf.random.set_seed(seed=net+(num-1)*10+123+off)
    
    global act_dam,act_dam_clone,act_rtpd,act_rtpd_clone,dam_len_lstm,dam_lstm1_ann,dam_lstm2_ann,dam_dense_ann
    global rtpd_len_lstm0,rtpd_len_lstm,rtpd_lstm0_ann,rtpd_lstm1_ann,rtpd_lstm2_ann,rtpd_dense_ann
    global len_input_lstm,params 
    
    tf.keras.backend.clear_session()
    
    DAM_params,RTPD_params=random_anns_params()
    [dam_len_lstm,dam_lstm1_ann,dam_lstm2_ann,dam_dense_ann]=DAM_params
    [rtpd_len_lstm0,rtpd_len_lstm,rtpd_lstm0_ann,rtpd_lstm1_ann,rtpd_lstm2_ann,rtpd_dense_ann]=RTPD_params
    len_input_lstm=max(dam_len_lstm,rtpd_len_lstm)
    params=horizon,dam_len_lstm,rtpd_len_lstm0,rtpd_len_lstm


    act_dam=DamActorNetwork(dam_len_lstm,dam_lstm1_ann,dam_lstm2_ann,dam_dense_ann)
    act_dam.create_network() # input: input_lstm1 (past),input_lstm2 (future),input_clock,input_rtpd,input_e0
    act_dam_clone=tf.keras.models.clone_model(act_dam.model)
    act_dam_clone=update_target(act_dam,act_dam_clone,1)

    act_rtpd=RtpdActorNetwork(rtpd_len_lstm0,rtpd_len_lstm,rtpd_lstm0_ann,rtpd_lstm1_ann,rtpd_lstm2_ann,rtpd_dense_ann)
    act_rtpd.create_network() #input_e0,input_reloj,input_seq_lstm,input_seq_lstm_future
    act_rtpd_clone=tf.keras.models.clone_model(act_rtpd.model)
    act_rtpd_clone=update_target(act_rtpd,act_rtpd_clone,1)
    act_dam.optimizer=tf.keras.optimizers.RMSprop()
    act_rtpd.optimizer=tf.keras.optimizers.RMSprop()
        
    tr_buffer=get_data(len_input_lstm,"tr",horizon,num)
    val_buffer=get_data(len_input_lstm,"val",horizon,num) #var,VAR,P_dam,P_rtpd,Ebat
    initial_conditions=[tr_buffer[2],tr_buffer[3],tr_buffer[4],tr_buffer[5],tr_buffer[6]]
    
    plt.rcParams["figure.figsize"]=[16,2]
    conditions=initial_conditions
    plt.suptitle("Initial conditions",y=1.05,size=17)
    for j in range(5):
        plt.subplot(1,5,j+1)
        plt.title(["DAM schedule\n from 10:00 to 23:00","DAMru schedule\n from 10:00 to 23:00",
                   "DAMrd schedule\n from 10:00 to 23:00","RTPD schedule\n from 10:00 to 11:00","Battery charge\n 10:00"][j])
        plt.hist(initial_conditions[j].reshape(-1),bins=100,color=["r","orangered","navy","red","g"][j])
    plt.tight_layout()
    plt.show()
    print("TRAINING NEW NETWORK: ",
          dam_len_lstm,dam_lstm1_ann,dam_lstm2_ann,dam_dense_ann,
                  rtpd_len_lstm0,rtpd_len_lstm,rtpd_lstm0_ann,rtpd_lstm1_ann,rtpd_lstm2_ann,rtpd_dense_ann)
#     act_dam.model.summary()
#     act_rtpd.model.summary()
    local_val_loss,pat=-1e10,0

    rew_tr_h,rew_val_h=[],[]
    for epochs in range(EPOCHS):
        t1=time.time()
    ##########Training############
        with tf.GradientTape() as tape:
            tape.watch([act_dam.model.trainable_variables,act_rtpd.model.trainable_variables])
            rews,rew,tr_buffer,val_buffer=run("tr",batch_size,params,tr_buffer,val_buffer,
            plot=False,epochs=None,rew_tr=None,idx=None)
            DAM_grad,RTPD_grad=tape.gradient(-rews, [act_dam.model.trainable_variables,act_rtpd.model.trainable_variables])
            epoch=act_dam.optimizer.apply_gradients(zip(DAM_grad, act_dam.model.trainable_variables)).numpy()
            epoch=act_rtpd.optimizer.apply_gradients(zip(RTPD_grad, act_rtpd.model.trainable_variables)).numpy()
        rew_tr_h.append(rew)
        act_dam_clone=update_target(act_dam,act_dam_clone,1)
        act_rtpd_clone=update_target(act_rtpd,act_rtpd_clone,1)
        t2=time.time()
    ##########Validation############
        if epochs%10==0: verbose=True
        else: verbose=False
        rews_val,rew_val,tr_buffer,val_buffer=run("val",val_buffer[0].shape[0],params,tr_buffer,val_buffer,
            plot=verbose,epochs=epochs+1,rew_tr=rew,idx=None)
        rew_val_h.append(rew_val)
        t3=time.time()
        print("Epoch:",epochs+1," | REW_TR: ",np.round(rew_tr_h[-1],2),
                                                    " | REW_VAL: ",np.round(rew_val_h[-1],2),
                                                    " | Train time: ",
                                                    np.round(t2-t1,2)," | Validation time: ",
                                                    np.round(t3-t2,2))
        if rew_val_h[-1]>local_val_loss:
            local_val_loss=rew_val_h[-1]
            pat=0
            print("Best model - set "+str(num))
            conditions=[tr_buffer[2],tr_buffer[3],tr_buffer[4],tr_buffer[5],tr_buffer[6]]
            act_dam.model.save_weights("models/actor_weights_dam_"+str(num)+"- ann_"+str(net))
            act_rtpd.model.save_weights("models/actor_weights_rtm_"+str(num)+"- ann_"+str(net))
        else: pat+=1

        if pat==patience or epochs==EPOCHS-1:
            crom=[rew_tr_h,rew_val_h,DAM_params,RTPD_params,initial_conditions,conditions]
            with open("models/crom-"+str(num)+"- ann_"+str(net)+".txt", "wb") as fp:   #Pickling
                pickle.dump(crom, fp)
            print("Final best model - set "+str(num)+": "+str(local_val_loss))
            plt.rcParams["figure.figsize"]=[16,2]
            plt.suptitle("ANN training & validation loss",y=1.05,size=17)
            plt.plot(rew_tr_h,"r",label="Rew_tr")
            plt.plot(rew_val_h,"g",label="Rew_val")
            plt.xlabel("Loss")
            plt.ylabel("Epochs")
            plt.legend()
            plt.grid()
            plt.show()
            plt.rcParams["figure.figsize"]=[16,2]
            plt.suptitle("Final conditions",y=1.05,size=17)
            conditions=[tr_buffer[2],tr_buffer[3],tr_buffer[4],tr_buffer[5],tr_buffer[6]]
            for j in range(5):
                plt.subplot(1,5,j+1)
                plt.title(["DAM schedule\n from 10:00 to 23:00","DAMru schedule\n from 10:00 to 23:00",
                           "DAMrd schedule\n from 10:00 to 23:00","RTPD schedule\n from 10:00 to 11:00","Battery charge\n 10:00"][j])
                plt.hist(initial_conditions[j].reshape(-1),bins=100,color=["r","orangered","navy","red","g"][j])
            plt.tight_layout()
            plt.show()
            break
